{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Levenberg-Marquardt mothod for ordinary differential equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose is to produce\n",
    "1. $\\varphi(\\mathbf{z})$ that produces $n\\times(p+1)$-dimension vector with input arguments of function, initial condition $\\mathbf{y}_0$, and parameters $\\mathbf{k}$.\n",
    "2. Levenberg-Marquardt parameter estimation procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "from scipy.integrate import solve_ivp, odeint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ODE model and objective function\n",
    "For the intial value problem\n",
    "\\begin{equation}\n",
    "\\frac{\\text{d}\\mathbf{y}(t)}{\\text{d}t}=\\mathbf{f}(\\mathbf{y}(t),\\mathbf{k});\\hspace{10mm}\\mathbf{y}(t_0)=\\mathbf{y}_0\n",
    "\\end{equation}\n",
    "where $\\mathbf{k}$ is a parameter vector with $p$ elements, the objective function with the measurements $\\hat{\\mathbf{y}}_i$ ($i=1,\\cdots,N$) and the weighting matrix $\\mathbf{Q}_i$ is\n",
    "\\begin{equation}\n",
    "S(\\mathbf{k})=\\frac{1}{2}\\sum_{i=1}^N\\left[\\hat{\\mathbf{y}}_i-\\mathbf{y}(t_i,\\mathbf{k})\\right]^\\top\\mathbf{Q}_i\\left[\\hat{\\mathbf{y}}_i-\\mathbf{y}(t_i,\\mathbf{k})\\right]=\\frac{1}{2}\\sum_{i=1}^N\\mathbf{r}_i(\\mathbf{k})^\\top\\mathbf{Q}_i\\mathbf{r}_i(\\mathbf{k})\n",
    "\\end{equation}\n",
    "where $S(\\mathbf{k}):\\mathbb{R}^p\\to\\mathbb{R}$ and $\\mathbf{r}_i(\\mathbf{k})=\\hat{\\mathbf{y}}_i-\\mathbf{y}(t_i,\\mathbf{k})$ is the residuals. The gradient of the objective function is\n",
    "\\begin{equation}\n",
    "\\mathbf{g}=\\frac{\\partial S(\\mathbf{k})}{\\partial\\mathbf{k}}=-\\sum_{i=1}^N\\mathbf{J}_i^\\top\\mathbf{Q}_i\\mathbf{r}_i\n",
    "\\end{equation}\n",
    "and the Hessian is\n",
    "\\begin{align}\n",
    "\\mathbf{H}&=\\frac{\\partial^2S(\\mathbf{k})}{\\partial\\mathbf{k}^2}=\\sum_{i=1}^N\\mathbf{J}_i^\\top\\mathbf{Q}_i\\mathbf{J}_i-\\sum_{i=1}^N\\frac{\\partial\\mathbf{J^\\top}_i}{\\partial\\mathbf{k}}\\mathbf{Q}_i\\mathbf{r}_i\\\\\n",
    "&\\simeq\\sum_{i=1}^N\\mathbf{J}_i^\\top\\mathbf{Q}_i\\mathbf{J}_i\n",
    "\\end{align}\n",
    "where $\\mathbf{J}_i(\\mathbf{k})=\\frac{\\partial\\mathbf{y}(t_i,\\mathbf{k})}{\\partial\\mathbf{k}}$ is the Jacobian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Talyor expansion of scalar function of several variables\n",
    "The line passes $\\mathbf{x}_0$ along the direction $\\mathbf{s}$ is the set of points satisfying $\\mathbf{x}(\\alpha)=\\mathbf{x}_0+\\alpha\\mathbf{s}$ for all $\\alpha$. For a scalar value function $f(\\mathbf{x})$, the directional derivative of $f$ at $\\mathbf{x}_0$ in the direction of $\\mathbf{s}$ is,\n",
    "\\begin{equation}\n",
    "D_\\mathbf{s}f(\\mathbf{x}_0)=\\lim_{\\alpha\\to0}\\frac{f(\\mathbf{x}_0+\\alpha\\mathbf{s})-f(\\mathbf{x}_0)}{\\alpha}=\\frac{\\text{d}f(\\textbf{x})}{\\text{d}\\alpha}\\bigg|_{\\textbf{x}=\\textbf{x}_0}\n",
    "\\end{equation}\n",
    "By the chain rule,\n",
    "\\begin{equation}\n",
    "\\frac{\\text{d}}{\\text{d}\\alpha}=\\sum_i\\frac{\\partial}{\\partial x_i}\\frac{\\text{d}x_i(\\alpha)}{\\text{d}\\alpha}=\\sum_is_i\\frac{\\partial}{\\partial x_i}=\\mathbf{s^\\top \\nabla}\n",
    "\\end{equation}\n",
    "so the slope of $f$ along any line $\\mathbf{x}(\\alpha)$ is\n",
    "\\begin{equation}\n",
    "\\frac{\\text{d}f}{\\text{d}\\alpha}=\\mathbf{s}^\\top\\nabla f=\\nabla f^\\top\\mathbf{s}\n",
    "\\end{equation}\n",
    "and the curvature along the line is\n",
    "\\begin{equation}\n",
    "\\frac{\\text{d}^2 f}{\\text{d}\\alpha^2}=\\frac{\\text{d}}{\\text{d}\\alpha}\\frac{\\text{d}f}{\\text{d}\\alpha}=\\mathbf{s}^\\top\\nabla(\\nabla f^\\top\\mathbf{s})=\\mathbf{s}^\\top\\nabla^2f\\mathbf{s}.\n",
    "\\end{equation}.\n",
    "The Taylor expansion of multiple variables is\n",
    "\\begin{equation}\n",
    "f(\\mathbf{x}_0+\\alpha\\mathbf{s})=f(\\mathbf{x}_0)+\\alpha\\mathbf{s}^\\top\\nabla f(\\mathbf{x}_0)+\\frac{1}{2}\\alpha^2\\mathbf{s}^\\top\\left[\\nabla^2f(\\mathbf{x}_0)\\right]\\mathbf{s}+\\cdots\n",
    "\\end{equation}\n",
    "or\n",
    "\\begin{equation}\n",
    "f(\\mathbf{x}_0+\\mathbf{h})=f(\\mathbf{x}_0)+\\mathbf{h}^\\top\\nabla f(\\mathbf{x}_0)+\\frac{1}{2}\\mathbf{h}^\\top\\left[\\nabla^2f(\\mathbf{x}_0)\\right]\\mathbf{h}+\\cdots.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gauss-Newton method\n",
    "The Taylor expansion of $\\mathbf{r}_i$ respect to $\\mathbf{h}$ is\n",
    "$$\\mathbf{r}_i(\\mathbf{k+h})=\\mathbf{r}_i(\\mathbf{k})+\\frac{\\partial\\mathbf{r}_i(\\mathbf{k})}{\\partial\\mathbf{k}}\\mathbf{h}+\\mathcal{O}(\\mathbf{h^\\top h})=\\mathbf{r}_i(\\mathbf{k})-\\mathbf{J}_i(\\mathbf{k})\\mathbf{h}+\\mathcal{O}(\\mathbf{h^\\top h}).$$  \n",
    "In Gauss-Newton (GN) method, $\\mathbf{r}_i$ is approximated to a linear model\n",
    "\\begin{equation}\n",
    "\\mathbf{l}_i=\\mathbf{r}_i(\\mathbf{k})-\\mathbf{J}_i(\\mathbf{k})\\mathbf{h}\n",
    "\\end{equation}\n",
    "Inserting $\\mathbf{l}_i$ to the objective function yields\n",
    "\\begin{align}\n",
    "S(\\mathbf{k+h})&\\simeq L(\\mathbf{h})=\\frac{1}{2}\\sum_{i=1}^N\\mathbf{l}_i^\\top(\\mathbf{h})\\mathbf{Q}_i\\mathbf{l}_i(\\mathbf{h})\\\\\n",
    "    &=\\frac{1}{2}\\sum_{i=1}^N\\left[\\mathbf{r}_i\\mathbf{(k)}^\\top\\mathbf{Q}_i\\mathbf{r}_i\\mathbf{(k)}-\\mathbf{r}_i^\\top\\mathbf{Q}_i\\mathbf{J}_i\\mathbf{(k)h}-\\mathbf{h}^\\top\\mathbf{J}_i\\mathbf{(k)}^\\top\\mathbf{Q}_i\\mathbf{r}_i(\\mathbf{k})+\\mathbf{h}^\\top\\mathbf{J}_i\\mathbf{(k)}^\\top\\mathbf{Q}_i\\mathbf{J}_i\\mathbf{(k)}\\mathbf{h}\\right]\\\\\n",
    "    &=S(\\mathbf{k})-\\sum_{i=1}^N\\mathbf{h^\\top J}_i^\\top\\mathbf{Q}_i \\mathbf{r}_i+\\frac{1}{2}\\sum_{i=1}^N\\mathbf{h^\\top J}_i^\\top\\mathbf{Q}_i\\mathbf{J}_i\\mathbf{h}\n",
    "\\end{align}\n",
    "since $\\mathbf{r}_i^\\top\\mathbf{Q}_i\\mathbf{J}_i\\mathbf{(k)h}=\\mathbf{h}^\\top\\mathbf{J}_i\\mathbf{(k)}^\\top\\mathbf{Q}_i\\mathbf{r}_i(\\mathbf{k})$.  \n",
    "The gradient and Hessian of $L$ are\n",
    "\\begin{equation}\n",
    "\\mathbf{L'(h)}=\\sum_{i=1}^N\\left[-\\mathbf{J}_i^\\top\\mathbf{Q}_i\\mathbf{r}_i+\\mathbf{J}_i^\\top\\mathbf{Q}_i\\mathbf{J}_i\\mathbf{h}\\right]\\hspace{20mm}\\mathbf{L''(h)}=\\sum_{i=1}^N\\mathbf{J}_i^\\top\\mathbf{Q}_i\\mathbf{J}_i\n",
    "\\end{equation}\n",
    "The Hessian is independent of $\\mathbf{h}$, symmetric and positive definite if $\\mathbf{J}$ has full rank. Hence $L$ is minimum when $\\mathbf{L'(h)}$ is zero vector. The step $\\mathbf{h}$ can be calculated by,\n",
    "\\begin{equation}\n",
    "\\left[\\sum_{i=1}^N\\mathbf{J}_i^\\top\\mathbf{Q}_i\\mathbf{J}_i\\right]\\mathbf{h}=\\sum_{i=1}^N\\mathbf{J}_i^\\top\\mathbf{Q}_i\\mathbf{r}_i=\\sum_{i=1}^N\\mathbf{J}_i^\\top\\mathbf{Q}_i\\left(\\hat{\\mathbf{y}}_i-\\mathbf{y}(t_i,\\mathbf{k})\\right)\n",
    "\\end{equation}\n",
    "so that\n",
    "\\begin{equation}\n",
    "\\mathbf{Hh=-g}\n",
    "\\end{equation}\n",
    "GN method is not quadratic convergent if $\\mathbf{r}_i$ is not zero around the solution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Levenberg-Marquardt method\n",
    "In Levenberg-Marquardt (LM) method, GN method is used with a damping term,\n",
    "\\begin{equation*}\n",
    "\\left[\\sum_{i=1}^N\\mathbf{J}_i^\\top\\mathbf{Q}_i\\mathbf{J}_i+\\mu\\mathbf{I}\\right]\\mathbf{h}_\\text{lm}=\\sum_{i=1}^N\\mathbf{J}_i^\\top\\mathbf{Q}_i\\mathbf{r}_i\n",
    "\\end{equation*}\n",
    "For large $\\mu$, $\\mathbf{h}_\\text{lm}\\simeq-\\frac{1}{\\mu}\\mathbf{L'(0)}$ is a short step in the steepest descent direction. This is good if the estimation is far from the solution. If $\\mu$ is very small, LM method is nearly GN method which is almost quadratic convergent if $S(\\mathbf{k})$ is close to zero.\n",
    "### Initial $\\mu$\n",
    "The initial value of $\\mu$ is maximum diagonal element of $\\mathbf{H}_0=\\sum\\mathbf{J}_i(\\mathbf{k}_0)^\\top\\mathbf{Q}_i\\mathbf{J}_i(\\mathbf{k}_0)$,\n",
    "\\begin{equation*}\n",
    "\\mu_0=\\tau\\cdot\\max[\\text{diagonal}(\\mathbf{H}_0)]\n",
    "\\end{equation*}\n",
    "where $\\tau$ is small such as $10^{-6}$ if $\\mathbf{k}_0$ is believed to be a good approximation or large such as $10^{-3}$ or $1$ otherwise.\n",
    "### Gain ratio\n",
    "The updating of $\\mu$ is controlled by the gain ratio\n",
    "\\begin{equation*}\n",
    "\\rho=\\frac{S(\\mathbf{k})-S(\\mathbf{k+h}_\\text{lm})}{L(\\mathbf{0})-L(\\mathbf{h}_\\text{lm})}\n",
    "\\end{equation*}\n",
    "The denominator is the gain predicted by the linear model,\n",
    "\\begin{align*}\n",
    "L(\\mathbf{0})-L(\\mathbf{h}_\\text{lm})=&\\mathbf{h}_\\text{lm}^\\top\\sum_{i=1}^N\\mathbf{J}_i\\mathbf{Q}_i\\mathbf{r}_i-\\frac{1}{2}\\mathbf{h}^\\top_\\text{lm}\\left[\\sum_{i=1}^N\\mathbf{J}_i\\top\\mathbf{Q}_i\\mathbf{J}_i\\right]\\mathbf{h}_\\text{lm}\\\\\n",
    "                   =&\\frac{1}{2}\\mathbf{h}_\\text{lm}^\\top\\left(2\\sum_{i=1}^N\\mathbf{J}_i\\mathbf{Q}_i\\mathbf{r}_i-\\left[\\sum_{i=1}^N\\mathbf{J}^\\top_i\\mathbf{Q}_i\\mathbf{J}_i+\\mu\\mathbf{I}\\right]\\mathbf{h}_\\text{lm}+\\mu\\mathbf{I}\\mathbf{h}_\\text{lm}\\right)\\\\\n",
    "                   =&\\frac{1}{2}\\mathbf{h}_\\text{lm}^\\top\\left(\\sum_{i=1}^N\\mathbf{J}_i^\\top\\mathbf{Q}_i\\mathbf{r}_i+\\mu\\mathbf{h}_\\text{lm}\\right)\\\\\n",
    "                   =&\\frac{1}{2}\\mathbf{h}_\\text{lm}^\\top\\left(-\\mathbf{g}+\\mu\\mathbf{h}_\\text{lm}\\right)\n",
    "\\end{align*}\n",
    "A large value of $\\rho$ indicates that $L(\\mathbf{h}_\\text{lm})$ is a good approximation of $S(\\mathbf{k+h}_\\text{lm})$ so $\\mu$ can be decreased so that LM is closer to GN method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of Jacobian in ODE models\n",
    "In ODE models, the sensitivity matrix cannot be obtained by a simple differentiation. Instead, we can get differential equation for $\\mathbf{J}$.\n",
    "Differentiate both side of $ \\frac{\\text{d}\\mathbf{y}}{\\text{d}t}=\\mathbf{f}(\\mathbf{y}(t),\\mathbf{k})$ and apply the chain rule,\n",
    "\\begin{align}\n",
    "\\frac{\\partial}{\\partial\\mathbf{k}}\\left(\\frac{\\text{d}\\mathbf{y}}{\\text{d}t}\\right)=\\frac{\\text{d}}{\\text{d}t}\\left(\\frac{\\partial\\mathbf{y}}{\\partial\\mathbf{k}}\\right)&=\\frac{\\partial}{\\partial\\mathbf{k}}\\mathbf{f}(\\mathbf{y}(t),\\mathbf{k})\\\\\n",
    "&=\\frac{\\partial\\mathbf{f}}{\\partial\\mathbf{y}}\\frac{\\partial\\mathbf{y}}{\\partial\\mathbf{k}}+\\frac{\\partial\\mathbf{f}}{\\partial\\mathbf{k}}\\frac{\\partial\\mathbf{k}}{\\partial\\mathbf{k}}\\\\\n",
    "&=\\frac{\\partial\\mathbf{f}}{\\partial\\mathbf{y}}\\frac{\\partial\\mathbf{y}}{\\partial\\mathbf{k}}+\\frac{\\partial\\mathbf{f}}{\\partial\\mathbf{k}}\n",
    "\\end{align}\n",
    "Hence,\n",
    "\\begin{equation*}\n",
    "\\frac{\\text{d}\\mathbf{J}(t)}{\\text{d}t}=\\frac{\\partial\\mathbf{f}}{\\partial\\mathbf{y}}\\mathbf{J}(t)+\\frac{\\partial\\mathbf{f}}{\\partial\\mathbf{k}};\\hspace{10mm}\\mathbf{J}(t_0)=0\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contruction of ODE system with Jacobian\n",
    "The Jacobian or the sensitivity matrix is\n",
    "\\begin{equation}\n",
    "\\mathbf{J}(t)=\\frac{\\partial\\mathbf{y}}{\\partial\\mathbf{k}}=\\left[\\frac{\\partial\\mathbf{y}}{\\partial k_1},\\cdots,\\frac{\\partial\\mathbf{y}}{\\partial k_p}\\right]=[\\mathbf{g}_1,\\cdots,\\mathbf{g}_p]\n",
    "\\end{equation}\n",
    "where $\\mathbf{g}_j$ represents $n$-dimensional vector which is the sensitivity coefficients of the state variables with respect to parameter $k_j$. Each of $\\mathbf{g}_j$ satisfies the differential equation for Jacobian such that\n",
    "\\begin{equation*}\n",
    "\\frac{\\text{d}\\mathbf{g}_j(t)}{\\text{d}t}=\\frac{\\partial\\mathbf{f}}{\\partial\\mathbf{y}}\\mathbf{g}_j+\\frac{\\partial\\mathbf{f}}{\\partial k_j};\\hspace{10mm}\\mathbf{g}_j(t_0)=0;\\hspace{10mm}j=1,\\cdots,p\n",
    "\\end{equation*}\n",
    "We generate $n\\times(p+1)$-dimensional differential equations system\n",
    "\\begin{equation*}\n",
    "\\frac{d\\mathbf{z}}{dt}=\\varphi(\\mathbf{z})\n",
    "\\end{equation*}\n",
    "$\\mathbf{z}$ is $n\\times(p+1)$-dimensional vector\n",
    "\\begin{equation*}\n",
    "\\mathbf{z}=\\begin{bmatrix} \\mathbf{x}(t)\\\\\n",
    "                          \\frac{\\partial\\mathbf{y}}{\\partial k_1}\\\\\n",
    "                          \\vdots\\\\\n",
    "                          \\frac{\\partial\\mathbf{y}}{\\partial k_p}\n",
    "\\end{bmatrix}\n",
    "=\\begin{bmatrix} \\mathbf{y}(t)\\\\\n",
    "                 \\mathbf{g}_1(t)\\\\\n",
    "                 \\vdots\\\\\n",
    "                 \\mathbf{g}_p(t)\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "$\\mathbf{\\varphi}(\\mathbf{z})$ is $n\\times(p+1)$-dimensional vector function\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbf{\\varphi}(\\mathbf{z})=\\begin{bmatrix}\n",
    "\\mathbf{f}(\\mathbf{y},\\mathbf{k})\\\\\n",
    "\\frac{\\partial\\mathbf{f}}{\\partial\\mathbf{y}}\\mathbf{g}_1(t)+\\frac{\\partial\\mathbf{f}}{\\partial k_1}\\\\\n",
    "\\vdots\\\\\n",
    "\\frac{\\partial\\mathbf{f}}{\\partial\\mathbf{y}}\\mathbf{g}_p(t)+\\frac{\\partial\\mathbf{f}}{\\partial k_p}\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "To get the Jacobian for all $t_i$, $\\varphi(\\mathbf{z}_i)$ should be solved for $t_i,~~i=1,2,\\cdots,N$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrange of the solution\n",
    "The Jacobian $\\textbf{J}$ is obtained by integration of $\\varphi(z)$. Integration of $\\varphi(z)$ returns $n\\times(p+1)$ vector\n",
    "\\begin{equation*}\n",
    "\\textbf{z}=\\begin{bmatrix}\n",
    "\\textbf{y}\\\\\n",
    "\\textbf{g}_1\\\\\n",
    "\\textbf{g}_2\\\\\n",
    "\\vdots\\\\\n",
    "\\textbf{g}_p\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "where\n",
    "\\begin{equation*}\n",
    "\\textbf{g}_j=\\begin{bmatrix}\n",
    "\\frac{\\partial y_1}{\\partial k_j}\\\\\n",
    "\\frac{\\partial y_2}{\\partial k_j}\\\\\n",
    "\\vdots\\\\\n",
    "\\frac{\\partial y_n}{\\partial k_j}\n",
    "\\end{bmatrix},\\hspace{20mm}j=1,\\cdots,p\n",
    "\\end{equation*}\n",
    "To compute the Hessian\n",
    "\\begin{equation*}\n",
    "\\mathbf{H}=\\sum_{i=1}^N\\mathbf{J}(t_i)^\\top\\mathbf{Q}_i\\mathbf{J}(t_i)\n",
    "\\end{equation*}\n",
    "the Jacobian for all measurement time $\\mathbf{J}(t_1),\\cdots,\\mathbf{J}(t_N)$, should be returned.\n",
    "The ODE solver for initial value problem returns $[n\\times(p+1)]\\times N$ matrix\n",
    "\\begin{equation*}\n",
    "Z=\\begin{bmatrix}\n",
    "\\mathbf{y}(t_1)&\\mathbf{y}(t_2)&\\cdots&\\mathbf{y}(t_N)\\\\\n",
    "\\mathbf{g}_1(t_1)&\\mathbf{g}_1(t_2)&\\cdots&\\mathbf{g}_1(t_N)\\\\\n",
    "\\vdots&&\\ddots&\\vdots\\\\\n",
    "\\mathbf{g}_p(t_1)&\\mathbf{g}_p(t_2)&\\cdots&\\mathbf{g}_p(t_N)\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "This matrix would be refomulated for\n",
    "\\begin{equation*}\n",
    "\\textbf{Y}=\\begin{bmatrix}\n",
    "\\mathbf{y}(t_1)&\\mathbf{y}(t_2)&\\cdots&\\mathbf{y}(t_N)\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "and\n",
    "\\begin{align*}\n",
    "\\mathcal{J}=&\\begin{bmatrix}\n",
    "\\mathbf{J}(t_1),\\mathbf{J}(t_2),\\cdots,\\mathbf{J}(t_N)\n",
    "\\end{bmatrix}\\\\\n",
    "=&\\left[\\begin{bmatrix}\n",
    "\\textbf{g}_1(t_1)&\\textbf{g}_2(t_1)&\\cdots&\\textbf{g}_p(t_1)\n",
    "\\end{bmatrix}\n",
    ",\\cdots,\\begin{bmatrix}\n",
    "\\textbf{g}_1(t_N)&\\textbf{g}_2(t_N)&\\cdots&\\textbf{g}_p(t_N)\n",
    "\\end{bmatrix}\\right].\n",
    "\\end{align*}\n",
    "Note that $\\mathbf{Y}$ is an $n\\times N$ matrix and $\\mathcal{J}$ is an $n\\times p\\times N$ tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrator_jacobian(ode,y0,k,time):\n",
    "    n = np.size(y0)\n",
    "    p = np.size(k)\n",
    "    N = np.size(time)\n",
    "    # initial condition J0 = 0\n",
    "    z0 = np.zeros(n*(p+1))\n",
    "    z0[0:n] = y0\n",
    "    def dzdt(t,z):\n",
    "        return phi_ode(ode,z,k,n,p)\n",
    "    solution = solve_ivp(dzdt,[time[0],time[-1]],z0,method='Radau',t_eval=time)\n",
    "    if solution.success == False:\n",
    "        raise OverflowError(\"Integration by integrator_jacobian failed\")\n",
    "    Z = solution.y\n",
    "    Y = Z[0:n]\n",
    "    J = Z[n:]\n",
    "    Jt = np.hsplit(J,N)\n",
    "    for i in range(N):\n",
    "        Jt[i] = Jt[i].reshape(p,n).transpose()\n",
    "    return Y,Jt\n",
    "\n",
    "def phi_ode(ode,z,k,n,p):\n",
    "    y = z[0:n]\n",
    "    J = z[n:].reshape((p,n)).transpose()\n",
    "    phiz = np.empty(n*(p+1))\n",
    "    dfdy = dfdy_ode(ode,y,k,n)\n",
    "    dfdk = dfdk_ode(ode,y,k,n,p)\n",
    "    dJdt = dfdy@J+dfdk\n",
    "    phiz[0:n] = ode(y,k)\n",
    "    phiz[n:] = dJdt.transpose().flatten()\n",
    "    return phiz\n",
    "\n",
    "def dfdy_ode(ode,y,k,n):\n",
    "    h = 1e-8\n",
    "    y = y.astype(np.float)\n",
    "    if np.isscalar(y):\n",
    "        dfdy = (ode(y+h,k)-ode(y-h,k))/(2*h)\n",
    "        return dfdy\n",
    "    else:\n",
    "        dfdy = np.empty((n,n))\n",
    "        for i in range(n):\n",
    "            yr = y.copy()\n",
    "            yl = y.copy()\n",
    "            yr[i] += h\n",
    "            yl[i] -= h\n",
    "            dfdy[i] = (ode(yr,k)-ode(yl,k))/(2*h)\n",
    "        return dfdy.transpose()\n",
    "    return\n",
    "\n",
    "def dfdk_ode(ode,y,k,n,p):\n",
    "    h = 1e-8\n",
    "    if p == 1:\n",
    "        dfdk = (ode(y,k+h)-ode(y,k-h))/(2*h)\n",
    "        return dfdk.reshape(n,1)\n",
    "    else:\n",
    "        k = k.astype(np.float)\n",
    "        dfdk = np.empty((p,n))\n",
    "        for i in range(p):\n",
    "            kr = k.copy()\n",
    "            kl = k.copy()\n",
    "            kr[i] += h\n",
    "            kl[i] -= h\n",
    "            dfdk[i] = (ode(y,kr)-ode(y,kl))/(2*h)\n",
    "        return dfdk.transpose()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduced Jacobian\n",
    "The Hessian $\\mathbf{H}$ might be ill-conditioned if the paramters differ by several order of magnitude. To overcome numerical problem, reduced Jacobian $\\mathbf{J}_\\text{R}$ is defined as\n",
    "$$\\mathbf{J}_\\text{R}=\\mathbf{JK}$$\n",
    "where $\\mathbf{K}=\\text{diag}(k_1,\\cdots,k_p)$. Then we can solve\n",
    "$$\\mathbf{H}_\\text{R}\\mathbf{h}_\\text{R}=-\\mathbf{g}_\\text{R}$$\n",
    "where $\\mathbf{H}_\\text{R}=\\mathbf{KHK}$ and $\\mathbf{g}_\\text{R}=\\mathbf{Kg}$.\n",
    "We can restore $\\textbf{h}$ from $\\textbf{h=Kh}_\\text{R}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm of LM method\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm(ode,yhat,Q,k0,time,opts=[1e-3,1e-8,1e-8,1000]):\n",
    "    # Input arguments\n",
    "\n",
    "    # opts = [tau, tolg, tolk, max_iter]\n",
    "    #\n",
    "    # Outputs\n",
    "    # output = [k,Y,info]\n",
    "    # k : parameters\n",
    "    # Y : results with k\n",
    "    # info = [it,ter]\n",
    "    # it : Number of iterations\n",
    "    # ter : Termination criteria 1: gradient 2: change in h 3: maximum iteration\n",
    "\n",
    "    try:\n",
    "        stop = False\n",
    "        nu = 2\n",
    "        it = 0  \n",
    "        rho = 0\n",
    "        ter = 'm'\n",
    "        if np.size(yhat) == np.size(yhat,0):\n",
    "            y0 = yhat[0]\n",
    "            N = np.size(yhat)\n",
    "        else:\n",
    "            y0 = yhat[:,0]\n",
    "            N = np.size(yhat,1)\n",
    "        p = np.size(k0)\n",
    "        I = np.eye(p)\n",
    "        k = k0\n",
    "        print('Iter | Obj func | red grad | lin appr |   mu   |   rho')\n",
    "        Y, J = integrator_jacobian(ode,y0,k,time)\n",
    "        S, r = objective_func(yhat,Y,Q,N)\n",
    "        S0 = S\n",
    "        H,g = Hg(J,Q,r,p,N)\n",
    "        K = np.diag(k)\n",
    "        Hr = K@H@K\n",
    "        gr = K@g\n",
    "        gn = LA.norm(gr,np.inf)\n",
    "        stop = bool(gn < opts[1])\n",
    "        if stop:\n",
    "            ter = 'g'\n",
    "        mu = opts[0]*max(np.diag(Hr))\n",
    "        print(\"{0:5d}|{1:10.4e}|{2:10.2e}|  Not cal |{3:8.1e}| Not cal\"\n",
    "              .format(it,S,gn,mu))\n",
    "        while (not stop) and (it<=opts[3]):\n",
    "            it += 1\n",
    "            hr = svdsolve(Hr+mu*I,-gr)\n",
    "            dphi = np.dot(hr,gr)\n",
    "            print(dphi)\n",
    "            h = K@hr\n",
    "            hn = LA.norm(h,np.inf)\n",
    "            kn = LA.norm(k,np.inf)\n",
    "            if hn <= opts[2]*(kn+opts[2]):\n",
    "                stop = True\n",
    "                ter = 'h'\n",
    "            else:\n",
    "                k_new = k + h\n",
    "                Y, J = integrator_jacobian(ode,y0,k_new,time)\n",
    "                S, r = objective_func(yhat,Y,Q,N)\n",
    "                lin = h.T@(mu*h-g)/2\n",
    "                rho = (S0 - S)/lin\n",
    "                if rho >0:\n",
    "                    k = k_new \n",
    "                    K = np.diag(k)\n",
    "                    S0 = S\n",
    "                    H, g = Hg(J,Q,r,p,N)\n",
    "                    Hr = K@H@K\n",
    "                    gr = K@g\n",
    "                    gn = LA.norm(gr,np.inf) \n",
    "                    if gn < opts[1]:\n",
    "                        stop = True\n",
    "                        ter = 'g'\n",
    "                    mu *= max(1/3,1-(2*rho-1)**3)\n",
    "                    nu = 2\n",
    "                else:\n",
    "                    mu *= nu\n",
    "                    nu *= 2\n",
    "            if rho == 0:\n",
    "                print(\"{0:5d}|{1:10.4e}|{2:10.2e}|{3:10.2e}|{4:8.1e}| Not calculated\"\n",
    "                      .format(it,S,gn,lin,mu))\n",
    "            else:\n",
    "                print(\"{0:5d}|{1:10.4e}|{2:10.2e}|{3:10.2e}|{4:8.1e}|{5:8.1e}\"\n",
    "                      .format(it,S,gn,lin,mu,rho))\n",
    "        info = [it,ter]\n",
    "        output = [k,Y,info]\n",
    "        return output\n",
    "    except OverflowError:\n",
    "        print(\"Problem with integration. Try with another parameter\")\n",
    "        return\n",
    "\n",
    "def objective_func(yhat,Y,Q,N):\n",
    "    S = 0\n",
    "    r = yhat-Y\n",
    "    if np.size(Q) == 1:\n",
    "        S = np.sum(r**2)/2\n",
    "    else:\n",
    "        for i in range(N):\n",
    "            # S += np.dot(np.matmul(r[:,i],Q),r[:,i])\n",
    "            S += r[:,i]@Q@r[:,i]/2\n",
    "    return S, r\n",
    "\n",
    "def Hg(J,Q,r,p,N):\n",
    "    H = np.zeros((p,p))\n",
    "    g = np.zeros(p)\n",
    "    for i in range(N):\n",
    "        JQ = J[i].T@Q\n",
    "        H += JQ@J[i]\n",
    "        g -= JQ@r[:,i]\n",
    "    return H,g\n",
    "\n",
    "def svdsolve(A,b):\n",
    "    u,s,v = np.linalg.svd(A)\n",
    "    c = u.T@b\n",
    "    w = np.linalg.solve(np.diag(s),c)\n",
    "    x = v.T@w\n",
    "    return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
